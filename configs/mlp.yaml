model:
  base_learning_rate: 2.0e-06
  target: models.wrapper.StyleLatentDiffusion
  params:
    linear_start: 0.0015
    linear_end: 0.0205
    log_every_t: 100
    timesteps: 1000
    loss_type: l1
    first_stage_key: image
    cond_stage_key: coordinates_bbox
    image_size: 512
    channels: 1
    concat_mode: false
    conditioning_key: crossattn
    parameterization: x0
    cond_stage_trainable: true
    unet_config:
      target: models.timestep_networks.MLPNet
      params:
        noise_size: 512
        context_size: 1024
        depth: 32
        use_fp16: False
    first_stage_config:
      target: ldm.models.autoencoder.IdentityFirstStage
      params:
        vq_interface: false
    cond_stage_config:
      target: ldm.modules.encoders.modules.OpenCLIPEncoder
      params:
        scale_factor: 1.0
        type: cls
    style_gan_config:
      target: models.wrapper.StyleGANWrapper
      params:
        generator_pth: weights/photomat/G_512.pkl
        decoder_pth: weights/photomat/MatUnet_512.pt
        num_ws: 16
        use_fp16: false
    monitor: val/loss_simple_ema

dataloader:
  # RandomNoiseDataLoader
  params:
    seed: 12345
    count: 1000000
    dim: 512
