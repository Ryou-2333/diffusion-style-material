model:
  base_learning_rate: 2.0e-06
  target: models.wrapper.StyleLatentDiffusion
  params:
    linear_start: 0.0015
    linear_end: 0.0205
    log_every_t: 100
    timesteps: 1000
    loss_type: l1
    first_stage_key: image
    cond_stage_key: coordinates_bbox
    image_size: 512
    channels: 1
    concat_mode: false
    conditioning_key: crossattn
    parameterization: x0
    cond_stage_trainable: true
    unet_config:
      target: models.time_embed_networks.AttentionPooledUNet
      params:
        image_size: 512
        concat_size: 0
        dims: 1
        in_channels: 1
        out_channels: 1
        model_channels: 128
        attention_resolutions:
        - 8
        - 4
        - 2
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 3
        - 4
        num_head_channels: 32
        use_spatial_transformer: false
        transformer_depth: 3
        conv_resample: false
        use_fp16: false
    first_stage_config:
      target: ldm.models.autoencoder.IdentityFirstStage
      params:
        vq_interface: false
    cond_stage_config:
      target: ldm.modules.encoders.modules.OpenCLIPEncoder
      params:
        scale_factor: 1.0
        type: cls
    style_gan_config:
      target: models.style_gan_wrapper.StyleGANWrapper
      params:
        generator_pth: weights/photomat/G_512.pkl
        decoder_pth: weights/photomat/MatUnet_512.pt
        num_ws: 16
        use_fp16: false
    monitor: val/loss_simple_ema

dataloader:
  # RandomNoiseDataLoader
  params:
    seed: 12345
    count: 1000000
    dim: 512
